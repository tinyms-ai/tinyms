{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mighty-private",
   "metadata": {},
   "source": [
    "# TinyMS ResNet50 Server Tutorial\n",
    "\n",
    "### In this tutorial, starting a ResNet50 inference server using TinyMS API will be demonstrated. \n",
    "\n",
    "## Prerequisite\n",
    " - Ubuntu: `18.04`\n",
    " - Python: `3.7.x`\n",
    " - Flask: `1.1.2`\n",
    " - MindSpore: `CPU-1.1.0`\n",
    " - TinyMS: `0.1.0`\n",
    " - numpy: `1.17.5`\n",
    " - opencv-python: `4.5.1.48`\n",
    " - Pillow: `8.1.0`\n",
    " - pip: `21.0.1`\n",
    " - requests: `2.18.4`\n",
    " \n",
    "## Introduction\n",
    "\n",
    "TinyMS is a high-level API which is designed for amateur of deep learning. It minimizes the number of actions of users required to construct, train, evaluate and serve a model. TinyMS also provides tutorials and documentations for developers. \n",
    "\n",
    "In this tutorial, the ckpt file will be provided since training ResNet50 on CPU is time consuming, so there are three steps to start a server: get the ckpt file, define servable json,and start the server. Making a prediction will be performed in `ResNet50_Client_tutorial.ipynb` file.\n",
    "\n",
    "\n",
    "## Steps\n",
    "\n",
    "### 1. Get the ckpt file\n",
    "\n",
    "The ResNet50 model we used in this tutorial was trained with [ImageNet2012](http://www.image-net.org/challenges/LSVRC/2012/) dataset. In the server, a ResNet50 ckpt file is required for the backend to run the prediction. We recommend clicking [here](https://ascend-tutorials.obs.cn-north-4.myhuaweicloud.com/resnet-50/ckpt_files/resnet-90_209.ckpt) to download the pretrained ResNet50 checkpoint file and save this file to `/etc/tinyms/serving/resnet50`.\n",
    "\n",
    "\n",
    "### 2. Define servable.json\n",
    "\n",
    "Define the resnet50 servable json file for model name, format and number of classes for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "servable_json = [{'name': 'resnet50', \n",
    "                  'description': 'This servable hosts a resnet50 model predicting mushroom', \n",
    "                  'model': {\n",
    "                      \"name\": \"resnet50\", \n",
    "                      \"format\": \"ckpt\", \n",
    "                      \"class_num\": 9}}]\n",
    "os.chdir(\"/etc/tinyms/serving\")\n",
    "json_data = json.dumps(servable_json, indent=4)\n",
    "\n",
    "with open('servable.json', 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-minnesota",
   "metadata": {},
   "source": [
    "### 3. Start server\n",
    "\n",
    "TinyMS Serving is a C/S(client/server) structure. There is a server and client. TinyMS using [Flask](https://flask.palletsprojects.com/en/1.1.x/) whichi is a micro web framework written in python as the C/S communication tool. In order to serve a model, user must start server first. If successfully started, the server will listen to POST requests from 127.0.0.1 port 5000 sent by client and handle the requests using MindSpore backend which will construct the model, run the prediction and send the result back to the client.  \n",
    "\n",
    "Run the following code block to start the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyms.serving import *\n",
    "\n",
    "# start(): start the server, call this function at the server side\n",
    "start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-thumb",
   "metadata": {},
   "source": [
    "If you can see the output similar to this:\n",
    "```\n",
    "* Serving Flask app \"serving.server.server\" (lazy loading)\n",
    " * Environment: production\n",
    "   WARNING: This is a development server. Do not use it in a production deployment.\n",
    "   Use a production WSGI server instead.\n",
    " * Debug mode: off\n",
    " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
    " ```\n",
    " that means the TinyMS serving server is already running. Next, go to `ResNet50_Client_tutorial.ipynb` to continue.\n",
    " \n",
    " ## Shutdown server\n",
    " \n",
    " To shut down server, if using terminal, simply CTRL + C to shutdown serving, if running in Jupyter, click `Kernel` at the top and then `Shutdown`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
