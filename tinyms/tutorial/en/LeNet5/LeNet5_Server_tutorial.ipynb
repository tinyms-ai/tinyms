{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-convenience",
   "metadata": {},
   "source": [
    "# TinyMS LeNet5 Server Tutorial\n",
    "\n",
    "### In this tutorial, constructing a LeNet model, downloading dataset , training and and start the server of the model using TinyMS API will be demonstrated. \n",
    "\n",
    "## Prerequisite\n",
    " - Ubuntu: `18.04`\n",
    " - Python: `3.7.x`\n",
    " - Flask: `1.1.2`\n",
    " - MindSpore: `CPU-1.1.0`\n",
    " - TinyMS: `0.1.0`\n",
    " - numpy: `1.17.5`\n",
    " - opencv-python: `4.5.1.48`\n",
    " - Pillow: `8.1.0`\n",
    " - pip: `21.0.1`\n",
    " - requests: `2.18.4`\n",
    " \n",
    "## Introduction\n",
    "\n",
    "TinyMS is a high-level API which is designed for amateur of deep learning. It minimizes the number of actions of users required to construct, train, evaluate and serve a model. TinyMS also provides tutorials and documentations for developers. \n",
    "\n",
    "This tutorial consists of five parts, constructing the model, downloading dataset, training, define servable json and starting server, while sending a prediction request will be demonstrated in the `LeNet5_Client_tutorial.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tinyms as ts\n",
    "import tinyms.optimizers as opt\n",
    "from tinyms.data import MnistDataset, download_dataset\n",
    "from tinyms.data.transforms import TypeCast\n",
    "from tinyms.vision import Inter, Resize, Rescale, HWC2CHW\n",
    "from tinyms.model import lenet5\n",
    "from tinyms.model import Model\n",
    "from tinyms.serving import *\n",
    "from tinyms.metrics import Accuracy\n",
    "from tinyms.losses import SoftmaxCrossEntropyWithLogits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-medline",
   "metadata": {},
   "source": [
    "## 1. Construct the model\n",
    "\n",
    "TinyMS encapsulates init and construct of the LeNet5 model, the line of the code is reduced and the following code has similar functions to this:\n",
    "\n",
    "```\n",
    "    import mindspore.nn as nn\n",
    "\n",
    "    class LeNet5(nn.Cell):\n",
    "        def __init__(self, num_class=10, num_channel=1):\n",
    "            super(LeNet5, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(num_channel, 6, 5, pad_mode='valid')\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5, pad_mode='valid')\n",
    "            self.relu = nn.ReLU()\n",
    "            self.max_pool2d = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.flatten = nn.Flatten()\n",
    "            self.fc1 = nn.Dense(16 * 5 * 5, 120, weight_init=Normal(0.02))\n",
    "            self.fc2 = nn.Dense(120, 84, weight_init=Normal(0.02))\n",
    "            self.fc3 = nn.Dense(84, num_class, weight_init=Normal(0.02))\n",
    "\n",
    "        def construct(self, x):\n",
    "            x = self.max_pool2d(self.relu(self.conv1(x)))\n",
    "            x = self.max_pool2d(self.relu(self.conv2(x)))\n",
    "            x = self.flatten(x)\n",
    "            x = self.relu(self.fc1(x))\n",
    "            x = self.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    net = LeNet(class_num=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = lenet5(class_num=10)\n",
    "model = Model(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-activation",
   "metadata": {},
   "source": [
    "## 2. Download dataset\n",
    "\n",
    "The MNIST dataset will be downloaded if `mnist` folder didn't exist at the root. If `mnist` folder already exists, this step will not be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_path, batch_size=32, repeat_size=1,\n",
    "                   num_parallel_workers=1):\n",
    "    \"\"\" create Mnist dataset for train or eval.\n",
    "    Args:\n",
    "        data_path: Data path\n",
    "        batch_size: The number of data records in each group\n",
    "        repeat_size: The number of replicated data records\n",
    "        num_parallel_workers: The number of parallel workers\n",
    "    \"\"\"\n",
    "    # define dataset\n",
    "    mnist_ds = MnistDataset(data_path, num_parallel_workers=num_parallel_workers,\n",
    "                            shuffle=True)\n",
    "\n",
    "    # define map operations\n",
    "    c_trans = [\n",
    "        Resize((32, 32), interpolation=Inter.LINEAR),  # Resize images to (32, 32)\n",
    "        Rescale(1 / 0.3081, -1 * 0.1307 / 0.3081),  # normalize images\n",
    "        Rescale(1.0 / 255.0, 0.0),  # rescale images\n",
    "        HWC2CHW(),  # change shape from (height, width, channel) to (channel, height, width) to fit network\n",
    "    ]\n",
    "    type_cast_op = TypeCast(ts.int32)  # change data type of label to int32 to fit network\n",
    "\n",
    "    # apply map operations on images\n",
    "    mnist_ds = mnist_ds.map(operations=type_cast_op, input_columns=\"label\", num_parallel_workers=num_parallel_workers)\n",
    "    mnist_ds = mnist_ds.map(operations=c_trans, input_columns=\"image\", num_parallel_workers=num_parallel_workers)\n",
    "    # apply batch operations\n",
    "    mnist_ds = mnist_ds.batch(batch_size, drop_remainder=True)\n",
    "    # apply repeat operations\n",
    "    mnist_ds = mnist_ds.repeat(repeat_size)\n",
    "\n",
    "    return mnist_ds\n",
    "\n",
    "# download the dataset\n",
    "if not os.path.exists('/root/mnist'):\n",
    "    ts.data.download_dataset('mnist', '/root')\n",
    "    print('************Download complete*************')\n",
    "else:\n",
    "    print('************Dataset already exists.**************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-bradford",
   "metadata": {},
   "source": [
    "## 3. Train the model\n",
    "\n",
    "The dataset for both training and evaluation will be defined here, and the parameters for training also set in this process. A trained ckpt file will be saved to `/etc/tinyms/serving/lenet5` folder for later use, meanwhile the evaluation will be performed and the `Accuracy` can be checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the training and evaluation dataset\n",
    "mnist_path = '/root/mnist'\n",
    "batch_size = 32\n",
    "train_dataset = create_dataset(os.path.join(mnist_path, \"train\"), batch_size=batch_size)\n",
    "eval_dataset = create_dataset(os.path.join(mnist_path, \"test\"))\n",
    "\n",
    "# parameters for training\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "epoch_size = 1\n",
    "net_loss = SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\n",
    "net_opt = opt.Momentum(net.trainable_params(), lr, momentum)\n",
    "net_metrics={\"Accuracy\": Accuracy()}\n",
    "\n",
    "model.compile(loss_fn=net_loss, optimizer=net_opt, metrics=net_metrics)\n",
    "print('************************Start training*************************')\n",
    "model.train(epoch_size, train_dataset)\n",
    "model.save_checkpoint('/etc/tinyms/serving/lenet5/lenet5.ckpt')\n",
    "print('************************Finished training*************************')\n",
    "\n",
    "model.load_checkpoint('/etc/tinyms/serving/lenet5/lenet5.ckpt')\n",
    "print('************************Start evaluation*************************')\n",
    "model.eval(eval_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-hazard",
   "metadata": {},
   "source": [
    "## 4. Define servable.json\n",
    "\n",
    "Define the lenet5 servable json file for model name, format and number of classes for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "servable_json = [{'name': 'lenet5', \n",
    "                  'description': 'This servable hosts a lenet5 model predicting numbers', \n",
    "                  'model': {\n",
    "                      \"name\": \"lenet5\", \n",
    "                      \"format\": \"ckpt\", \n",
    "                      \"class_num\": 10}}]\n",
    "os.chdir(\"/etc/tinyms/serving\")\n",
    "json_data = json.dumps(servable_json, indent=4)\n",
    "\n",
    "with open('servable.json', 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-matthew",
   "metadata": {},
   "source": [
    "## 5. Start server\n",
    "\n",
    "### 5.1 Introduction\n",
    "TinyMS Serving is a C/S(client/server) structure. TinyMS using [Flask](https://flask.palletsprojects.com/en/1.1.x/) whichi is a micro web framework written in python as the C/S communication tool. In order to serve a model, user must start server first. If successfully started, the server will listen to POST requests from 127.0.0.1 port 5000 sent by client and handle the requests using MindSpore backend which will construct the model, run the prediction and send the result back to the client.\n",
    "\n",
    "### 5.2 Start server\n",
    "\n",
    "run the following code block to start the server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-chick",
   "metadata": {},
   "source": [
    "If you can see somethin similar to this:\n",
    "```\n",
    "* Serving Flask app \"tinyms.serving.server.server\" (lazy loading)\n",
    " * Environment: production\n",
    "   WARNING: This is a development server. Do not use it in a production deployment.\n",
    "   Use a production WSGI server instead.\n",
    " * Debug mode: off\n",
    " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
    "```\n",
    "that means you have successfully launched a server. Next, go to 'LeNet5_Client_tutorial.ipynb' to continue.\n",
    "\n",
    "## Shutdown server\n",
    "\n",
    "To shut down server, if using terminal, simply CTRL + C to shutdown serving, if running in Jupyter, click `Kernel` at the top and then `Shutdown`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
