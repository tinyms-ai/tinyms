{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mighty-private",
   "metadata": {},
   "source": [
    "# TinyMS ResNet50 服务器端教程\n",
    "\n",
    "### 在本教程中，我们会演示获取ResNet50 ckpt文件和使用TinyMS API启动推理服务器的过程。\n",
    "\n",
    "## 环境要求\n",
    " - Ubuntu: `18.04`\n",
    " - Python: `3.7.x`\n",
    " - Flask: `1.1.2`\n",
    " - MindSpore: `CPU-1.1.0`\n",
    " - TinyMS: `0.1.0`\n",
    " - numpy: `1.17.5`\n",
    " - opencv-python: `4.5.1.48`\n",
    " - Pillow: `8.1.0`\n",
    " - pip: `21.0.1`\n",
    " - requests: `2.18.4`\n",
    " \n",
    "## 介绍\n",
    "\n",
    "TinyMS是一个高级API，目的是让新手用户能够更加轻松地上手深度学习。TinyMS可以有效地减少用户在构建、训练、验证和推理一个模型过程中的操作次数。TinyMS也提供了教程和文档帮助开发者更好的上手和开发。\n",
    "\n",
    "本教程中，由于使用CPU训练ResNet50模型过于耗时，所以本教程将直接提供训练好的ResNet50 ckpt文件。步骤包含3部分：获取ckpt文件、定义servable json和启动服务器，而进行推理操作的部分会在 `ResNet50_Client_tutorial_zh.ipynb`文件中进行讲解。\n",
    "\n",
    "\n",
    "## 步骤\n",
    "\n",
    "### 1. 获取ckpt文件\n",
    "\n",
    "本教程中使用的ResNet50模型由[ImageNet2012](http://www.image-net.org/challenges/LSVRC/2012/)数据集训练得来。启动推理服务器的前提条件是需要ResNet50 ckpt文件，可以点击[这里](https://ascend-tutorials.obs.cn-north-4.myhuaweicloud.com/resnet-50/ckpt_files/resnet-90_209.ckpt)下载ResNet50 ckpt文件并且保存到`/etc/tinyms/serving/resnet50`\n",
    "\n",
    "### 2. 定义servable.json\n",
    "\n",
    "定义lenet5 servable json文件，Servable json文件定义了servable名称，模型名称，模型格式和分类数量，以便后续推理使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "servable_json = [{'name': 'resnet50', \n",
    "                  'description': 'This servable hosts a resnet50 model predicting mushroom', \n",
    "                  'model': {\n",
    "                      \"name\": \"resnet50\", \n",
    "                      \"format\": \"ckpt\", \n",
    "                      \"class_num\": 9}}]\n",
    "os.chdir(\"/etc/tinyms/serving\")\n",
    "json_data = json.dumps(servable_json, indent=4)\n",
    "\n",
    "with open('servable.json', 'w') as json_file:\n",
    "    json_file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-jesus",
   "metadata": {},
   "source": [
    "### 3. 启动服务器\n",
    "\n",
    "TinyMS推理是C/S（Client/Server）架构。TinyMS使用[Flask](https://flask.palletsprojects.com/en/1.1.x/)这个轻量化的网页服务器架构作为C/S通讯的基础架构。为了能够对模型进行推理，用户必须首先启动服务器。如果成功启动，服务器端会监听从地址127.0.0.1，端口号5000发送来的POST请求并且使用MindSpore作为后端来处理这些请求。后端会构建模型，运行推理并且返回结果给客户端\n",
    "\n",
    "运行下列代码以启动服务器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinyms.serving import *\n",
    "\n",
    "# start(): start the server, call this function at the server side\n",
    "start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-thumb",
   "metadata": {},
   "source": [
    "如果用户能够看到类似如下的输出:\n",
    "```\n",
    "* Serving Flask app \"serving.server.server\" (lazy loading)\n",
    " * Environment: production\n",
    "   WARNING: This is a development server. Do not use it in a production deployment.\n",
    "   Use a production WSGI server instead.\n",
    " * Debug mode: off\n",
    " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
    " ```\n",
    "意味着服务器已经成功启动了，接下来的操作需要到`ResNet50_Client_tutorial_zh.ipynb`文件中完成\n",
    "\n",
    " \n",
    " ## 关闭服务器\n",
    " \n",
    "关闭服务器，如果使用终端，可以直接CTRL + C关闭，如果使用Jupyter，点击上方`Kernel`再点击`Shutdown`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
